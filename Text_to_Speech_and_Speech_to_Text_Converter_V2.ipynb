{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALL REQUIRED LIBRARIES**"
      ],
      "metadata": {
        "id": "R86eUoIwzVNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1406hoEDzIfq",
        "outputId": "ad46d5cb-711c-4fb6-b318-d23e116a43b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.2/3.2 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio transformers librosa gTTS gradio soundfile jiwer --quiet\n",
        "\n",
        "import torch\n",
        "import librosa\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD SPEECH-TO-TEXT MODEL**"
      ],
      "metadata": {
        "id": "CssaZBsXzdvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"facebook/wav2vec2-base-960h\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "1ac8f0ba43ea4d71ba2051d65bf93613",
            "d37e9b82b5154195bf09a6818a3862aa",
            "c779099ebc4446cfa27f6123bc21d3c3",
            "8f265365712d4070a2f4151b0191c396",
            "af2b4526539a40f39f4f589852e3ba54",
            "9255cc5f2fe94d31ac53bfe496a1c66e",
            "4a41020ac8794cf2964a84c844632ee7",
            "f5594c36253c437b8b455e8e95395c08",
            "cd8574725a8042dbbf8dbdb82283f3e6",
            "8f75e0668a2448379fc4a2f141464df8",
            "85e8787e106043ef9511c6c559db3fbb",
            "2c5958344cab4e35a27112900bc5e788",
            "a309662753144ca5a5f712cf5fbb516d",
            "ba5d4e08d2504ae4a001d54252f294a4",
            "8ea7f78369f5488fbb794c83fc4f798a",
            "8679c3c61ecb4b48b7462211ec919a76",
            "73aa7008325542249f0870a8fe511b02",
            "6cccea047a81422798fe3b10b7d1e817",
            "74c19c1d1a8d4509ae442eb7a3d0632d",
            "2f4d7ae1af024637963c81914098e871",
            "42f9540d24054b90901b33b6cdab23ac",
            "f142c3e73f724d7ca6686d01e7771425",
            "c86d1dfc89e4472fa421facc8334c8f7",
            "9f3020c179844c329d99f5658ef6c22c",
            "16cb35b1bd3543e19dcc56ed49340997",
            "95b9149be7ed48db9e1041da4cb51c83",
            "4771c96142be4a6aad8a80d5f5cdfc69",
            "924cf5c9ef344c53b24aa035328d7e3c",
            "a9fc917e77a24ef3b7c62988cc07cf94",
            "073c728940ac4b63a0b1a5a87fbefbe8",
            "09b2b1a3e42749de9a9e2a7446afca91",
            "7e8f39470af94beb93e2937f527652f4",
            "482ed880014f4755992c3027fa5a378b",
            "fda2e87519f84d9982b38981402b39a9",
            "b667b69071c941f29515bfc6de24b7e1",
            "f7071aea1c2b43c3911b8f3e6f823de5",
            "f3dd21268e5343ad98bb60c761a358ea",
            "0a15598f42544757a9abb0b3b44c29fd",
            "76168ec838cf4545aa07e0a837bbe856",
            "092bcd3ed57646668b29f9f270035c1c",
            "d88bf78c9f4d42ed840ab04b37bc057c",
            "db67675aeb444f70adc2cffd63370c72",
            "461c95baa8c24246a91aac461336e67f",
            "269b006750414831994c16b5736397ea",
            "6f48b25a492347a494a8d79543f89737",
            "2f119bcba0ec44dfb6bcb230c15a9020",
            "fde9f0ccd236467f8bfbd0e8839a3583",
            "866a1cb30f394d0c9a4f09c16bef76e2",
            "8d8465fac8164065bf0afb2807098360",
            "343d150622184bdc8a763940fc97c3ae",
            "a30e7a7694ba4fb1bc30146239225b2b",
            "f704d959e6af4827bdbf69999bb9bafb",
            "1f7610f739f94e7989360d52fc70db13",
            "f56e072123694198a42ef7fab01bfc89",
            "62054d35aac74027ab96e5cd659bb84c",
            "2840aa5845d84a1eba3cb04fb18b3a87",
            "79bac14e33274f6f9d1543ea5e2cbc5d",
            "b52e36f3dd2c40d0bc766ae8238116cb",
            "5e9d99d24c844291981fd2f2aedbf964",
            "2abcaeaafc98455ea12d63c7a1d0d5bc",
            "b9076dfa7840467bbb4c6b7cf2f64c7f",
            "d93a99b67a974cdca5dc4a4b74df48fc",
            "3ea531abb79d4002b259a9a99ce934a0",
            "9e3ab296a74944958acec8f82a5c642a",
            "3e9e6b813226430ba9358999fd40389e",
            "59e9bbc5fd874f89a12daab228f6563a"
          ]
        },
        "id": "_4g4fkeRzdLZ",
        "outputId": "13565729-b81e-431a-f278-0912cfabe249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ac8f0ba43ea4d71ba2051d65bf93613"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c5958344cab4e35a27112900bc5e788"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c86d1dfc89e4472fa421facc8334c8f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fda2e87519f84d9982b38981402b39a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f48b25a492347a494a8d79543f89737"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2840aa5845d84a1eba3cb04fb18b3a87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FUNCTION 1: TEXT TO SPEECH**"
      ],
      "metadata": {
        "id": "TN4UThZSzoeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(text: str) -> str:\n",
        "    \"\"\"Converts input text into speech (MP3 file).\"\"\"\n",
        "    out_path = \"generated_speech.mp3\"\n",
        "    tts = gTTS(text=text, lang=\"en\")\n",
        "    tts.save(out_path)\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "MF0dVmsPzt-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FUNCTION 2: SPEECH TO TEXT**"
      ],
      "metadata": {
        "id": "1r2ZJqLkzw16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text(audio_path: str) -> str:\n",
        "    \"\"\"Converts input audio into transcribed text.\"\"\"\n",
        "    if audio_path is None:\n",
        "        return \"Please upload or record an audio file.\"\n",
        "\n",
        "    speech, rate = librosa.load(audio_path, sr=16000)\n",
        "    input_values = processor(speech, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.decode(predicted_ids[0])\n",
        "    return transcription.lower()"
      ],
      "metadata": {
        "id": "ZzawlRBdz0J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT ACCURACY CHECK**"
      ],
      "metadata": {
        "id": "0eLnJ2F906yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(original_text: str, transcribed_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Compares original text vs transcribed text using Word Error Rate.\n",
        "    Returns accuracy percentage.\n",
        "    \"\"\"\n",
        "    if not original_text or not transcribed_text:\n",
        "        return \"Please enter both original and transcribed texts.\"\n",
        "\n",
        "    error_rate = wer(original_text.lower(), transcribed_text.lower())\n",
        "    accuracy = max(0, (1 - error_rate) * 100)\n",
        "    return f\"\u2705 Accuracy: {accuracy:.2f}%\\n(WER: {error_rate:.2f})\""
      ],
      "metadata": {
        "id": "rlQ0TKRq09Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRADIO APP**"
      ],
      "metadata": {
        "id": "4iv2Iv2rz5mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## \ud83c\udf99\ufe0f Deep Learning Project: Text \u2194 Speech Converter + Accuracy Checker\")\n",
        "\n",
        "    with gr.Tab(\"Text \u279d Speech\"):\n",
        "        text_input = gr.Textbox(label=\"Enter Text\", placeholder=\"Type something...\")\n",
        "        tts_button = gr.Button(\"Convert to Speech\")\n",
        "        audio_output = gr.Audio(label=\"Generated Speech\", type=\"filepath\")\n",
        "        tts_button.click(fn=text_to_speech, inputs=text_input, outputs=audio_output)\n",
        "\n",
        "    with gr.Tab(\"Speech \u279d Text\"):\n",
        "        audio_input = gr.Audio(label=\"Upload or Record Speech\", type=\"filepath\")\n",
        "        stt_button = gr.Button(\"Convert to Text\")\n",
        "        text_output = gr.Textbox(label=\"Recognized Text\")\n",
        "        stt_button.click(fn=speech_to_text, inputs=audio_input, outputs=text_output)\n",
        "\n",
        "    with gr.Tab(\"Accuracy Checker\"):\n",
        "        gr.Markdown(\"### Compare Original Text and Transcribed Text\")\n",
        "        orig_text = gr.Textbox(label=\"Original Text\", placeholder=\"Enter the original text...\")\n",
        "        trans_text = gr.Textbox(label=\"Transcribed Text\", placeholder=\"Enter the recognized text...\")\n",
        "        acc_button = gr.Button(\"Check Accuracy\")\n",
        "        acc_output = gr.Textbox(label=\"Result\", interactive=False)\n",
        "        acc_button.click(fn=check_accuracy, inputs=[orig_text, trans_text], outputs=acc_output)\n"
      ],
      "metadata": {
        "id": "VvzvUnrjz7L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN APP**"
      ],
      "metadata": {
        "id": "eo_9WxJcz-To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "Ob3ffe6a0Bju",
        "outputId": "0fe0a0e3-7387-4a3c-e235-b2c01506085c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://46069113385e4717ee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://46069113385e4717ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}